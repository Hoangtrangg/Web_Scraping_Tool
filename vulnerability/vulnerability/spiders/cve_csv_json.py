import scrapy
import csv
import json


class CveCsvJsonSpider(scrapy.Spider):
    name = "cve_csv_json"
    allowed_domains = ["cve.mitre.org"]
    start_urls = ["https://cve.mitre.org/data/refs/refmap/source-EXPLOIT-DB.html"]

    def parse(self, response):
        for child in response.xpath('//table'):
            if len(child.xpath('//tr'))>100:
                table = child
                break

        # That's the iterable that's going to set the CSV file for the writing
        csv_file = open('vulnerability.csv','w') 
        writer = csv.writer(csv_file)
        writer.writerow(['exploit_id','cve_id']) # this row mean writer the header 
        # of each column in file csv

        # write to a json file
        data = {} # create an empty dictionary
        json_file = open('vulnerability.json','w')
        
        #

        count = 0
        for row in table.xpath('//tr'):
            if count>100:
                break
            try:
                exploit_id = row.xpath('td//text()')[0].extract()
                cve_id = row.xpath('td//text()')[2].extract()
                #csv
                writer.writerow([exploit_id, cve_id]) # write a single row include 
                # a couple of exploit_id and cve_id to each row in csv file

                #json
                data[exploit_id] = cve_id # each item in dictionary has key is 
                                            # exploit_id and it's value is cve_id
                count+=1
            except IndexError:
                pass

        csv_file.close()

        json.dump(data, json_file)
        json_file.close()
